# -*- coding: utf-8 -*-
"""LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PTDXjAyj1WdbUp4xL-WuQC6X14LD31Tx
"""

import requests

from huggingface_hub import snapshot_download
from pathlib import Path
import requests
import re
import requests


model_dir = Path("arch_function")
repo_id = 'katanemo/Arch-Function-1.5B'

model_dir.mkdir(parents=True, exist_ok=True)
hf_token = "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"

snapshot_download(repo_id=repo_id, local_dir=str(model_dir), token=hf_token)

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

model_dir = "./arch_function"

# Load model and tokenizer from local files
tokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_dir, local_files_only=True, trust_remote_code=True)


# Move model to GPU if available
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
model.eval()

# Define available tools
get_weather_api = {
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get the current weather for a location",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "str",
                    "description": "The city and state, e.g. San Francisco, New York",
                },
                "unit": {
                    "type": "str",
                    "enum": ["celsius", "fahrenheit"],
                    "description": "The unit of temperature to return",
                },
            },
            "required": ["location"],
        },
    },
}

# Function to get the price of an object
get_price_api = {
    "type": "function",
    "function": {
        "name": "get_price",
        "description": "Get the current price of a product",
        "parameters": {
            "type": "object",
            "properties": {
                "object_name": {
                    "type": "str",
                    "description": "The name of the product, e.g., 'laptop', 'smartphone'"
                },
                "currency": {
                    "type": "str",
                    "enum": ["USD", "EUR", "GBP"],
                    "description": "The currency in which the price should be returned"
                },
            },
            "required": ["object_name"],
        },
    },
}

# Function to get the address of a shop
get_shop_address_api = {
    "type": "function",
    "function": {
        "name": "get_shop_address",
        "description": "Retrieve the address of a specific shop",
        "parameters": {
            "type": "object",
            "properties": {
                "shop_name": {
                    "type": "str",
                    "description": "The name of the shop, e.g., 'Coffee Corner', 'Tech World'"
                },
                "city": {
                    "type": "str",
                    "description": "The city where the shop is located"
                },
            },
            "required": ["shop_name"],
        },
    },
}


global_search_api = {
    "type": "function",
    "function": {
        "name": "global_search",
        "description": "When users query has something related to a question. Fetch general information from Google Search and summarise the results. Use this function when the user asks for general information or the other functions cannot resolve the query see if the query can be search on google.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "str",
                    "description": "The search query to look up on Google."
                }
            },
            "required": ["query"]
        },
    },
}


# Example of aggregating all available function definitions
tools = [get_weather_api, global_search_api, get_price_api, get_shop_address_api]

import json
from typing import Any, Dict, List

# Please use our provided prompt for best performance
TASK_PROMPT = """
You are a helpful assistant.

""".strip()

TOOL_PROMPT = """
# Tools

You may call one or more functions to assist with the user query.
You are provided with function signatures within <tools></tools> XML tags:
<tools>
{tool_text}
</tools>
""".strip()

FORMAT_PROMPT = """
For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call>
""".strip()


def convert_tools(tools: List[Dict[str, Any]]):
    return "\n".join([json.dumps(tool) for tool in tools])

# Helper function to create the system prompt for our model
def format_prompt(tools: List[Dict[str, Any]]):
    tool_text = convert_tools(tools)

    return (
        TASK_PROMPT
        + "\n\n"
        + TOOL_PROMPT.format(tool_text=tool_text)
        + "\n\n"
        + FORMAT_PROMPT
        + "\n"
    )

### Dummy function implementations ###
def get_weather(arguments):
    return {"name": "get_weather", "results": {"temperature": "62°", "unit": "fahrenheit"}}

def get_price(arguments):
    object_name = arguments.get("object_name", "unknown object")
    currency = arguments.get("currency", "USD")
    return {"name": "get_price", "results": {"object": object_name, "price": "100", "currency": currency}}

def get_shop_address(arguments):
    shop_name = arguments.get("shop_name", "unknown shop")
    city = arguments.get("city", "unknown city")
    return {"name": "get_shop_address", "results": {"shop_name": shop_name, "address": f"123 {shop_name} Ave, {city}"}}


def global_search(arguments):
    summary="Google is called to search for "+str(arguments)
    return {"name": "global_search", "results": summary}



# Map function names to the corresponding dummy functions
function_mapping = {
    "get_weather": get_weather,
    "get_price": get_price,
    "get_shop_address": get_shop_address,
    "global_search": global_search,
}

system_prompt = format_prompt(tools)
print(format_prompt(tools))

### Start a conversation
user_input = input("User: ")
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_input},
]

### Generate initial response (expected to output a tool call)
# We use the model's chat template (assuming your tokenizer supports it)
inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt").to(device)
outputs = model.generate(
    inputs,
    max_new_tokens=256,
    do_sample=False,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
)
response = tokenizer.decode(outputs[0][len(inputs[0]) :], skip_special_tokens=True)
print("Initial Model Output:\n", response)

### Parse the tool call from the model output
match = re.search(r"<tool_call>(.*?)</tool_call>", response, re.DOTALL)
if match:
    tool_call_json = match.group(1).strip()
    try:
        tool_call = json.loads(tool_call_json)
    except Exception as e:
        print("Failed to parse tool call:", e)
        tool_call = None
else:
    tool_call = None

### Define dummy function implementations for our tools
def get_weather(arguments):
    return {"name": "get_weather", "results": {"temperature": "62°", "unit": "fahrenheit"}}

def get_price(arguments):
    object_name = arguments.get("object_name", "unknown object")
    currency = arguments.get("currency", "USD")
    return {"name": "get_price", "results": {"object": object_name, "price": "100", "currency": currency}}

def get_shop_address(arguments):
    shop_name = arguments.get("shop_name", "unknown shop")
    city = arguments.get("city", "unknown city")
    return {"name": "get_shop_address", "results": {"shop_name": shop_name, "address": f"123 {shop_name} Ave, {city}"}}

# Map function names to dummy implementations
function_mapping = {
    "get_weather": get_weather,
    "get_price": get_price,
    "get_shop_address": get_shop_address,
}

### Execute the tool call if valid
execution_results = []
if tool_call and "name" in tool_call:
    func_name = tool_call["name"]
    arguments = tool_call.get("arguments", {})
    if func_name in function_mapping:
        result = function_mapping[func_name](arguments)
        execution_results.append(result)
    else:
        execution_results.append({"name": func_name, "results": "Function not found"})
else:
    execution_results.append({"error": "No valid tool call detected"})

print("Execution Results:\n", execution_results)

### Append execution results to conversation
def add_execution_results(messages: List[Dict[str, Any]], execution_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    content = "\n".join([f"<tool_response>\n{json.dumps(result)}</tool_response>" for result in execution_results])
    messages.append({"role": "user", "content": content})
    return messages

messages = add_execution_results(messages, execution_results)

### Generate final response using updated conversation
inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt").to(device)
outputs = model.generate(
    inputs,
    max_new_tokens=256,
    do_sample=False,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
)
final_response = tokenizer.decode(outputs[0][len(inputs[0]) :], skip_special_tokens=True)
print("Final Response:\n", final_response)